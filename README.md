# Memory Layers with CPU Pinned Memory

CPU Pinned Memoryë¥¼ í™œìš©í•œ Memory Layer êµ¬í˜„ì²´ì…ë‹ˆë‹¤. ì›ë³¸ [Memory Layers at Scale](https://ai.meta.com/research/publications/memory-layers-at-scale/) ë…¼ë¬¸ì„ ê¸°ë°˜ìœ¼ë¡œ í•˜ë©°, CPU ë©”ëª¨ë¦¬ì— ëŒ€ìš©ëŸ‰ ì„ë² ë”©ì„ ì €ì¥í•˜ê³  GPUì—ì„œ í•„ìš”í•œ ë¶€ë¶„ë§Œ ê°€ì ¸ì˜¤ëŠ” ë°©ì‹ìœ¼ë¡œ GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ìµœì†Œí™”í•©ë‹ˆë‹¤.

## ì£¼ìš” íŠ¹ì§•

- **CPU Pinned Memory**: PyTorchì˜ pinned memoryë¥¼ ì´ìš©í•œ íš¨ìœ¨ì ì¸ CPU-GPU ì „ì†¡
- **Unique Indices ìµœì í™”**: ì¤‘ë³µ ì¸ë±ìŠ¤ ì œê±°ë¡œ ì „ì†¡ëŸ‰ ìµœì†Œí™”
- **ëŒ€ìš©ëŸ‰ ë©”ëª¨ë¦¬ ë ˆì´ì–´**: Product Key Memory ê¸°ë°˜
- **ìµœì í™”ëœ í•™ìŠµ**: FP16 mixed precision, BFloat16 ì••ì¶• ì „ì†¡

## í”„ë¡œì íŠ¸ êµ¬ì¡°

```
ğŸ“¦memory
 â”£ ğŸ“‚lingua                    # í•µì‹¬ ë¼ì´ë¸ŒëŸ¬ë¦¬
 â”ƒ â”£ ğŸ“‚product_key            # Memory layer êµ¬í˜„
 â”ƒ â”ƒ â”£ ğŸ“œmemory.py            # Product Key Memory ë©”ì¸ ë¡œì§
 â”ƒ â”ƒ â”£ ğŸ“œzero_copy.py         # CPU Pinned Memory êµ¬í˜„
 â”ƒ â”ƒ â”— ğŸ“œcolwise_embeddingbag.py
 â”ƒ â”— ğŸ“œtransformer.py
 â”£ ğŸ“‚apps/main                # ë©”ì¸ í•™ìŠµ ì•±
 â”ƒ â”£ ğŸ“œtrain.py               # í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸
 â”ƒ â”— ğŸ“‚configs                # ì„¤ì • íŒŒì¼ë“¤
 â”£ ğŸ“‚setup                    # í™˜ê²½ êµ¬ì„± ìŠ¤í¬ë¦½íŠ¸
 â”£ ğŸ“‚agi_test                 # ì‹¤í—˜ ì„¤ì • ë° ìŠ¤í¬ë¦½íŠ¸
 â”— ğŸ“‚tokenizer                # í† í¬ë‚˜ì´ì €
```

## Quick Start

### 1. í™˜ê²½ êµ¬ì„±

```bash
# ì €ì¥ì†Œ í´ë¡ 
git clone <repository-url>
cd memory

# Conda í™˜ê²½ ìƒì„± ë° íŒ¨í‚¤ì§€ ì„¤ì¹˜
bash setup/create_env.sh

# í™˜ê²½ í™œì„±í™”
conda activate prj_hs
```

**í•„ìˆ˜ ìš”êµ¬ì‚¬í•­:**
- Python 3.11
- CUDA 12.1
- PyTorch 2.5.0
- xformers

### 2. ë°ì´í„° ì¤€ë¹„

```bash
# Hugging Face ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ë° ì¤€ë¹„
python setup/download_prepare_hf_data.py fineweb_edu_10bt <MEMORY_GB> \
    --data_dir ./data \
    --seed 42

# í† í¬ë‚˜ì´ì € ë‹¤ìš´ë¡œë“œ (Llama3)
python setup/download_tokenizer.py llama3 ./tokenizer \
    --api_key <HUGGINGFACE_TOKEN>
```

### 3. í•™ìŠµ ì‹¤í–‰

#### ë‹¨ì¼ GPU
```bash
CUDA_VISIBLE_DEVICES=0 python -m apps.main.train \
    config=agi_test/test_1/config/zero_copy.yaml
```

#### ì‹¤í—˜ ìŠ¤í¬ë¦½íŠ¸ ì‚¬ìš©
```bash
bash agi_test/test_1/script/zero_copy_train.sh
```

## ì„¤ì • ê°€ì´ë“œ

ì£¼ìš” ì„¤ì • íŒŒì¼: [agi_test/test_1/config/zero_copy.yaml](agi_test/test_1/config/zero_copy.yaml)

### CPU Pinned Memory ê´€ë ¨ ì„¤ì •

```yaml
model:
  productkey_args:
    zero_copy: true           # CPU Pinned Memory í™œì„±í™”
    mem_offload: false        # FPGA offload ë¹„í™œì„±í™”
    mem_n_keys: 8000          # ë©”ëª¨ë¦¬ í‚¤ ê°œìˆ˜
    mem_share_values: true    # Value sharing í™œì„±í™”
    mem_knn: 32               # K-nearest neighbors
    mem_k_dim: 512            # Key dimension
```

### ë°˜ë“œì‹œ ìˆ˜ì •í•´ì•¼ í•  ê²½ë¡œ

1. `data.root_dir`: ë°ì´í„° ë””ë ‰í† ë¦¬ ê²½ë¡œ
2. `data.tokenizer.path`: í† í¬ë‚˜ì´ì € ê²½ë¡œ
3. `dump_dir`: ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ê²½ë¡œ (ìŠ¤í¬ë¦½íŠ¸ì—ì„œ ì§€ì •)

## í‰ê°€ (Evaluation)

```bash
# ì²´í¬í¬ì¸íŠ¸ í‰ê°€
python -m apps.main.eval config=agi_test/test_1/config/eval_zero_copy.yaml
```

í‰ê°€ íƒœìŠ¤í¬: HellaSwag, PIQA, NQ Open

## í•µì‹¬ êµ¬í˜„

### CPU Pinned Memory Layer

ë©”ëª¨ë¦¬ ê°’(values)ì„ GPU ë©”ëª¨ë¦¬ê°€ ì•„ë‹Œ CPU pinned memoryì— ì €ì¥í•˜ì—¬ GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ìµœì†Œí™”í•©ë‹ˆë‹¤.

**ì£¼ìš” ìµœì í™” ê¸°ë²•:**

1. **Unique Indices**: ì¤‘ë³µ ì¸ë±ìŠ¤ ì œê±°ë¡œ CPU-GPU ì „ì†¡ëŸ‰ ê°ì†Œ
2. **Pinned Memory**: CPU ë©”ëª¨ë¦¬ë¥¼ piní•˜ì—¬ ë¹ ë¥¸ ì „ì†¡
3. **BFloat16 ì••ì¶•**: ì „ì†¡ ì‹œ BFloat16ìœ¼ë¡œ ì••ì¶•í•˜ì—¬ ëŒ€ì—­í­ ì ˆì•½
4. **Non-blocking Transfer**: ë¹„ë™ê¸° ì „ì†¡ìœ¼ë¡œ ëŒ€ê¸° ì‹œê°„ ìµœì†Œí™”

```python
# lingua/product_key/zero_copy.py
class ZeroCopy(nn.Module):
    def __init__(self, num_embeddings, embedding_dim):
        # CPU pinned memoryì— ê°’ ì €ì¥
        self.weight = nn.Parameter(
            torch.empty(num_embeddings, embedding_dim, device="cpu").pin_memory()
        )

    def forward(self, indices, scores):
        # 1. GPUì—ì„œ ì¤‘ë³µ ì¸ë±ìŠ¤ ì œê±°
        unique_indices, inverse = torch.unique(indices.flatten(), return_inverse=True)
        # 2. CPUì—ì„œ ì„ë² ë”© lookup
        unique_emb_cpu = self.weight[unique_indices.cpu()]
        # 3. BFloat16ë¡œ ì••ì¶•í•˜ì—¬ GPUë¡œ ì „ì†¡
        unique_emb_gpu = unique_emb_cpu.to(dtype=torch.bfloat16, device=indices.device)
        # 4. ì›ë³¸ shape ë³µì› ë° weighted sum
        return weighted_sum(unique_emb_gpu[inverse], scores)
```

## ì£¼ìš” í•˜ì´í¼íŒŒë¼ë¯¸í„°

| íŒŒë¼ë¯¸í„° | ê¸°ë³¸ê°’ | ì„¤ëª… |
|---------|--------|------|
| `mem_n_keys` | 8000 | ë©”ëª¨ë¦¬ í‚¤ ê°œìˆ˜ |
| `mem_knn` | 32 | ê²€ìƒ‰í•  nearest neighbors |
| `mem_k_dim` | 512 | í‚¤ ì„ë² ë”© ì°¨ì› |
| `mem_heads` | 2 | ë©”ëª¨ë¦¬ í—¤ë“œ ìˆ˜ |
| `batch_size` | 2 | ë°°ì¹˜ í¬ê¸° |
| `seq_len` | 4096 | ì‹œí€€ìŠ¤ ê¸¸ì´ |

## ë¬¸ì œ í•´ê²°

### CUDA Out of Memory
- `batch_size` ì¤„ì´ê¸°
- `mem_n_keys` ì¤„ì´ê¸°
- `PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True` ì„¤ì •

## ì›ë³¸ ë…¼ë¬¸ ë° ì½”ë“œ

ì´ ì½”ë“œëŠ” [Meta Lingua](https://github.com/facebookresearch/lingua)ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•˜ë©°, zero-copy ê¸°ëŠ¥ì´ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.

## Citation

```
@misc{memory_layers_scale,
  author = {Vincent-Pierre Berges, Barlas Oguz, Daniel Haziza, Wen-tau Yih, Luke Zettlemoyer, Gargi Gosh},
  title = {Memory Layers at Scale},
  url = {https://github.com/facebookresearch/memory},
  year = {2024}
}
```

## License

CC-BY-NC license
